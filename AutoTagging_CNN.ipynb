{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_questions = pd.read_hdf('auto_tagging_data_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
       "      <td>[hypothesis-testing, t-test, p-value, interpretation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
       "      <td>[correlation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                               Title  \\\n",
       "0   6                  The Two Cultures: statistics vs. machine learning?   \n",
       "1  21                                      Forecasting demographic census   \n",
       "2  22                 Bayesian and frequentist reasoning in plain English   \n",
       "3  31  What is the meaning of p values and t values in statistical tests?   \n",
       "4  36          Examples for teaching: Correlation does not mean causation   \n",
       "\n",
       "                                                                                                                                                                                                      Body  \\\n",
       "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n",
       "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n",
       "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n",
       "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n",
       "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n",
       "\n",
       "                                                    Tags  \n",
       "0                                     [machine-learning]  \n",
       "1                                          [forecasting]  \n",
       "2                                             [bayesian]  \n",
       "3  [hypothesis-testing, t-test, p-value, interpretation]  \n",
       "4                                          [correlation]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and body\n",
    "df_questions['Text'] = df_questions[\"Title\"] + \" \" + df_questions[\"Body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove html tags and url links\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # remove everything alphabets\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    # remove whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Text'].apply(lambda x: clean_text(x))\n",
    "df_questions['Text'] = df_questions['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21065</th>\n",
       "      <td>8916</td>\n",
       "      <td>are there any available implementations of density or conditional density tree learning greetings i am working on joint and conditional density trees for approximating clique potentials in bayesia...</td>\n",
       "      <td>[bayesian, multivariate-analysis, cart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63629</th>\n",
       "      <td>145620</td>\n",
       "      <td>error bars on graph skewed data negative standard deviation i have only had basic stats i conducted some research where i have four different treatments and results for the data range from i don t...</td>\n",
       "      <td>[standard-deviation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27069</th>\n",
       "      <td>99983</td>\n",
       "      <td>clustering data that has mixture of continuous and categorical variables i have data that represent some aspect of human behavior i want to cluster it unsupervised into behavioral profiles of some...</td>\n",
       "      <td>[r, clustering, categorical-data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52762</th>\n",
       "      <td>52842</td>\n",
       "      <td>orthogonal sets of variables in multiple imputation separate imputation models first thanks to those who gave me useful input on this project in a previous thread on this site i ve got a new ish q...</td>\n",
       "      <td>[missing-data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47853</th>\n",
       "      <td>94700</td>\n",
       "      <td>how to interpret the expression of ma as ar infty when ar is expressed as ma infty i can interpret it as let s say my wage this year depends only on last year s wage and a random shock my boss moo...</td>\n",
       "      <td>[time-series]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  \\\n",
       "21065    8916   \n",
       "63629  145620   \n",
       "27069   99983   \n",
       "52762   52842   \n",
       "47853   94700   \n",
       "\n",
       "                                                                                                                                                                                                          Text  \\\n",
       "21065  are there any available implementations of density or conditional density tree learning greetings i am working on joint and conditional density trees for approximating clique potentials in bayesia...   \n",
       "63629  error bars on graph skewed data negative standard deviation i have only had basic stats i conducted some research where i have four different treatments and results for the data range from i don t...   \n",
       "27069  clustering data that has mixture of continuous and categorical variables i have data that represent some aspect of human behavior i want to cluster it unsupervised into behavioral profiles of some...   \n",
       "52762  orthogonal sets of variables in multiple imputation separate imputation models first thanks to those who gave me useful input on this project in a previous thread on this site i ve got a new ish q...   \n",
       "47853  how to interpret the expression of ma as ar infty when ar is expressed as ma infty i can interpret it as let s say my wage this year depends only on last year s wage and a random shock my boss moo...   \n",
       "\n",
       "                                          Tags  \n",
       "21065  [bayesian, multivariate-analysis, cart]  \n",
       "63629                     [standard-deviation]  \n",
       "27069        [r, clustering, categorical-data]  \n",
       "52762                           [missing-data]  \n",
       "47853                            [time-series]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions[['Id', 'Text', 'Tags']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81956"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the two cultures statistics vs machine learning last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to this simon blomberg from r s fortunes package to paraphrase provocatively machine learning is statistics minus any checking of models and assumptions brian d ripley about the difference between machine learning and statistics user vienna may season s greetings andrew gelman in that case maybe we should get rid of checking of models and assumptions more often then maybe we d be able to solve some of the problems that the machine learning people can solve but we can t there was also the statistical modeling the two cultures paper by leo breiman in which argued that statisticians rely too heavily on data modeling and that machine learning techniques are making progress by instead relying on the predictive accuracy of models has the statistics field changed over the last decade in response to these critiques do the two cultures still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines \n",
      "\n",
      "[1, 59, 9730, 255, 315, 482, 256, 577, 277, 2, 333, 3, 2733, 374, 36, 24159, 665, 20232, 9413, 255, 315, 482, 256, 12412, 11, 2734, 60, 5, 1, 441, 74, 1, 59, 2265, 3603, 3384, 5009, 18773, 4, 12, 6933, 50267, 36, 45, 34, 38034, 250, 4, 14051, 50268, 482, 256, 6, 255, 2548, 68, 1771, 5, 132, 7, 691, 9140, 70, 9568, 89, 1, 167, 74, 482, 256, 7, 255, 600, 21877, 264, 1580, 34, 10105, 3603, 3384, 8, 11, 143, 580, 54, 83, 103, 3655, 5, 1771, 5, 132, 7, 691, 92, 726, 81, 580, 54, 70, 19, 375, 4, 588, 60, 5, 1, 597, 11, 1, 482, 256, 320, 28, 588, 31, 54, 28, 17, 43, 97, 105, 1, 235, 772, 1, 59, 9730, 433, 55, 16689, 7210, 8, 47, 6113, 11, 3184, 3258, 427, 3024, 21, 13, 772, 7, 11, 482, 256, 865, 18, 912, 3570, 55, 424, 6334, 21, 1, 785, 406, 5, 132, 100, 1, 255, 1056, 1670, 186, 1, 577, 8085, 8, 234, 4, 94, 15913, 48, 1, 59, 9730, 330, 1223, 33, 100, 255, 6392, 4, 16690, 482, 256, 865, 164, 25, 478, 886, 7, 855, 270, 2100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(df_questions['Text'][i], '\\n'), print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = []\n",
    "\n",
    "for i in sequences:\n",
    "    seq_lengths.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th percentile:  97.0\n",
      "40th percentile:  116.0\n",
      "50th percentile:  137.0\n",
      "60th percentile:  162.0\n",
      "70th percentile:  193.0\n",
      "80th percentile:  238.0\n",
      "90th percentile:  320.0\n",
      "95th percentile:  411.0\n",
      "99th percentile:  678.0\n"
     ]
    }
   ],
   "source": [
    "print(\"30th percentile: \", pd.Series(seq_lengths).quantile(0.3))\n",
    "print(\"40th percentile: \", pd.Series(seq_lengths).quantile(0.4))\n",
    "print(\"50th percentile: \", pd.Series(seq_lengths).quantile(0.5))\n",
    "print(\"60th percentile: \", pd.Series(seq_lengths).quantile(0.6))\n",
    "print(\"70th percentile: \", pd.Series(seq_lengths).quantile(0.7))\n",
    "print(\"80th percentile: \", pd.Series(seq_lengths).quantile(0.8))\n",
    "print(\"90th percentile: \", pd.Series(seq_lengths).quantile(0.9))\n",
    "print(\"95th percentile: \", pd.Series(seq_lengths).quantile(0.95))\n",
    "print(\"99th percentile: \", pd.Series(seq_lengths).quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 125\n",
    "\n",
    "# padding\n",
    "padded_seq = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions['Tags'])\n",
    "y = multilabel_binarizer.transform(df_questions['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76365, 125), (76365, 100))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(padded_seq, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_model(dropout_rate=0.0,filter_number=100,filter_size=3):\n",
    "    #model=Sequential()\n",
    "    #model.add(Embedding(vocab_size+1,128, input_length=max_length))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    #model.add(Conv1D(filter_number,filter_size,padding = 'valid', activation = \"relu\", strides = 1))\n",
    "    #model.add(GlobalMaxPool1D())\n",
    "    #model.add(Dense(100,activation=\"sigmoid\"))\n",
    "    #model.compile(optimizer=\"adam\",loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = [512]\n",
    "#epochs = [10]\n",
    "#dropout_rate = [0.1]\n",
    "#filter_number=[100,300,500]\n",
    "#filter_size=[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = dict(batch_size=batch_size, epochs=epochs,dropout_rate=dropout_rate,filter_number=filter_number,filter_size=filter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "#grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "    #print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size +1, 128, input_length = max_length))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Conv1D(300, 5, padding = 'valid', activation = \"relu\", strides = 1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100, activation = \"sigmoid\"))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 125, 128)          10490624  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 123, 300)          115500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "=================================================================\n",
      "Total params: 10,636,224\n",
      "Trainable params: 10,636,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "             EarlyStopping(patience=3),\n",
    "             ModelCheckpoint(filepath='model-conv1d_v1.h5', save_best_only=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54982 samples, validate on 6110 samples\n",
      "Epoch 1/15\n",
      "54982/54982 [==============================] - 224s 4ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.0551 - val_accuracy: 0.9828\n",
      "Epoch 2/15\n",
      "54982/54982 [==============================] - 226s 4ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.0562 - val_accuracy: 0.9825\n",
      "Epoch 3/15\n",
      "54982/54982 [==============================] - 225s 4ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 0.0571 - val_accuracy: 0.9825\n",
      "Epoch 4/15\n",
      "54982/54982 [==============================] - 224s 4ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.0589 - val_accuracy: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the code below to load the saved model\n",
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15273, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold to 0.45\n",
    "preds_int = (preds >= 0.45).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5046885934219735"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 score\n",
    "f1_score(y_val, preds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = q.lower()\n",
    "    q_seq = tokenizer.texts_to_sequences([q])\n",
    "    q_seq_padded = pad_sequences(q_seq, maxlen=125)\n",
    "    q_pred = model.predict(q_seq_padded)\n",
    "    q_pred = (q_pred >= 0.3).astype(int)\n",
    "    \n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prediction', 'r', 'regression')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give new question\n",
    "new_q = \"Regression line in ggplot doesn't match computed regression Im using R and created a chart using ggplot2. I then create a regression so I can make some predicitions I pass my data frame of to the predict function predict(regression, Measures) I'd expect the predictions to be the same as if I used the regression line on the chart, but they aren't the same. Why would this be the case? Is there a setting in ggplot or is my expectation incorrect?\"\n",
    "\n",
    "# get tags\n",
    "infer_tags(new_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search hyperparatmeters tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prediction', 'r', 'regression')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give new question\n",
    "new_q = \"Regression line in ggplot doesn't match computed regression Im using R and created a chart using ggplot2. I then create a regression so I can make some predicitions I pass my data frame of to the predict function predict(regression, Measures) I'd expect the predictions to be the same as if I used the regression line on the chart, but they aren't the same. Why would this be the case? Is there a setting in ggplot or is my expectation incorrect?\"\n",
    "\n",
    "# get tags\n",
    "infer_tags(new_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
